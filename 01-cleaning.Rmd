---
title: "Cleaning Data"
output:
  html_document:
    df_print: paged
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs") })
---

## Goals of this Notebook

- Import cheese price data
- Import cheese storage data
- Import production data
- Import milk/cheese consumption data
- Clean names and dates
- Write the cleaned data

## About the data

I collected cheese price data from the [United States Department of Agriculture (USDA)](https://mymarketnews.ams.usda.gov/public_data). It ranges from 2000 to 2022, and covers the region categories of Wisconsin, Western U.S., Midwestern U.S. and the  Northeastern U.S. region. The prices are in units of dollars per pound.

In addition to price data, I want to look at USDA data on the government's cheese storage holdings. I'll import that here and use it to compare in my analysis. Storage holdings data is in units of pounds, and comes from the USDA National Agricultural Statistics Service [Cold Storage Report](https://quickstats.nass.usda.gov/results/172E17CF-AD11-37D8-949A-0624FA6A9CD0).

You check out these [FAQs](https://mymarketnews.ams.usda.gov/faqs) about USDA market data.

## Updating the data

As I reported my story, I realized I need to look at American cheese production by pound as well. I downloaded cheese production data by state from the same database as my storage data, the National Agricultural Statistics Service within the USDA.

Similarly, I added consumption data for milk and cheese in pounds consumed per capita. This data came from the dairy consumption annual report from the USDA website.

## Setup

I'm loading the tidyverse library and lubridate package so I can clean up my data.

```{r setup}
library(tidyverse)
library(lubridate)
library(dplyr)
library(janitor)
library(tidyr)
```

## Import price data

I'll import all my files here, which range from January 2000 to November 2022. These reports fall under three regional categories, including Western U.S. cheese, Northeastern U.S. cheese and Midwestern U.S. cheese.

I downloaded each files from an API and put them in a folder called file list. I'll import and bind all the files into one tibble using the list.files function.

```{r list_import}
list_of_files <- list.files(path = "file-list", recursive = TRUE,
                            pattern = "\\.csv$", 
                            full.names = TRUE) #imports the file list

cheese_dirty <- list_of_files |> 
  purrr::set_names(nm = (basename("file-list") |>  tools::file_path_sans_ext())
) |> 
  purrr::map_df(read_csv, 
                col_names = TRUE) #sets names

cheese_dirty |> summary()
```

### Clean  price data

Now it's time to clean my data. I'll use mutate.if to change all the character values to upper case letters so I can search easily later on. I'll also clean up my column names. Then, I'll change the names of some of my columns to make it easier for me to analyze.

Finally, I'll select the columns I need for my analysis so I don't have to worry about the other ones. 

```{r names}
cheese_clean <- cheese_dirty |> 
  mutate_if(
    is.character, str_to_upper
) |> 
  clean_names(
) |>
  mutate(
    date = mdy(report_begin_date),
    high_price = price_max,
    low_price = price_min,
    type = group
) |> 
  select(
    date, region, high_price, low_price, type
  )

cheese_clean |> summary() #checking column names
```

### Adjust prices for inflation

Now I want to adjust my prices for inflation. I'll be using the [average yearly Consumer Price Index for Urban Consumers, or CPI-U](https://www.bls.gov/bls/archived_sched.htm) from the Bureau of Labor Statistics to calculate each year's cheese prices adjusted to 2015 dollars. First, I need to make a year column.

```{r yr}
cheese_yrs <- cheese_clean |>
  mutate(yr = year(date))

cheese_yrs |> summary()
```

Now I'll divide the average CPI for each year by the 2021 CPI. Then,  I'll multiply it by each price in order to get a column where every price in my data set is adjusted to 2021 dollars.

A CPI estimate for 2022 is based on the change in the CPI from first quarter 2021 to first quarter 2022.

```{r case_when}
adj_cheese <- cheese_yrs |>
  mutate(
    adj_high_price = case_when(
      yr == 2000 ~ high_price*271.0/172.2,
      yr == 2001 ~ high_price*271.0/177.1,
      yr == 2002 ~ high_price*271.0/179.9,
      yr == 2003 ~ high_price*271.0/184.0,
      yr == 2004 ~ high_price*271.0/188.9,
      yr == 2005 ~ high_price*271.0/195.3,
      yr == 2006 ~ high_price*271.0/201.6,
      yr == 2007 ~ high_price*271.0/207.3,
      yr == 2008 ~ high_price*271.0/215.3,
      yr == 2009 ~ high_price*271.0/214.3,
      yr == 2010 ~ high_price*271.0/218.1,
      yr == 2011 ~ high_price*271.0/224.9,
      yr == 2012 ~ high_price*271.0/229.6,
      yr == 2013 ~ high_price*271.0/233.0,
      yr == 2014 ~ high_price*271.0/236.7,
      yr == 2015 ~ high_price*271.0/237.0,
      yr == 2016 ~ high_price*271.0/240.0,
      yr == 2017 ~ high_price*271.0/245.1,
      yr == 2018 ~ high_price*271.0/251.1,
      yr == 2019 ~ high_price*271.0/255.7,
      yr == 2020 ~ high_price*271.0/258.8,
      yr == 2021 ~ high_price*271.0/271.0,
      yr == 2022 ~ high_price*271.0/294.4
      ),
  adj_low_price = case_when(
      yr == 2000 ~ low_price*271.0/172.2,
      yr == 2001 ~ low_price*271.0/177.1,
      yr == 2002 ~ low_price*271.0/179.9,
      yr == 2003 ~ low_price*271.0/184.0,
      yr == 2004 ~ low_price*271.0/188.9,
      yr == 2005 ~ low_price*271.0/195.3,
      yr == 2006 ~ low_price*271.0/201.6,
      yr == 2007 ~ low_price*271.0/207.3,
      yr == 2008 ~ low_price*271.0/215.3,
      yr == 2009 ~ low_price*271.0/214.3,
      yr == 2010 ~ low_price*271.0/218.1,
      yr == 2011 ~ low_price*271.0/224.9,
      yr == 2012 ~ low_price*271.0/229.6,
      yr == 2013 ~ low_price*271.0/233.0,
      yr == 2014 ~ low_price*271.0/236.7,
      yr == 2015 ~ low_price*271.0/237.0,
      yr == 2016 ~ low_price*271.0/240.0,
      yr == 2017 ~ low_price*271.0/245.1,
      yr == 2018 ~ low_price*271.0/251.1,
      yr == 2019 ~ low_price*271.0/255.7,
      yr == 2020 ~ low_price*271.0/258.8,
      yr == 2021 ~ low_price*271.0/271.0,
      yr == 2022 ~ low_price*271.0/294.4
    ))

adj_cheese |> summary() #checking columns
```

### Checking my prices with a calculator

Using this [inflation calculator](https://www.minneapolisfed.org/about-us/monetary-policy/inflation-calculator) from the Minneapolis Federal Reserve Bank website, I want to make sure I did this right by checking my adjusted prices from 2005 to 2021.

```{r check_calc}
adj_cheese |> 
  filter(yr == 2005) |> 
  head(5)
```

I tested these prices and the inflation checks out!

### Remove one bad row

First, I spoke with an expert on USDA reports about one row with an N/A price from 2018 - he said this row is a repeat leftover from combining the report.

I'll find that row here and get rid of it.

```{r adj}
adj_cheese |> 
  filter(is.na(low_price)) #check to make sure only one row in this column has an N/A value

clean_adj_cheese <- adj_cheese |> 
  drop_na() #removes all N/A rows

clean_adj_cheese |> glimpse() #check to make sure there is only one fewer row in the data - it should be 22,366
```

## Import storage data

```{r import_storage}
storage_dirty <- read_csv("data-raw/comprehensive_storage.csv")
```

### Clean storage data

```{r clean_storage}
storage_clean <- storage_dirty |> 
  clean_names() |> 
  mutate(
    month_names = case_when(
      period == "END OF JAN" ~ "Jan",
      period == "END OF FEB" ~ "Feb",
      period == "END OF MAR" ~ "Mar",
      period == "END OF APR" ~ "Apr",
      period == "END OF MAY" ~ "May",
      period == "END OF JUN" ~ "Jun",
      period == "END OF JUL" ~ "Jul",
      period == "END OF AUG" ~ "Aug",
      period == "END OF SEP" ~ "Sep",
      period == "END OF OCT" ~ "Oct",
      period == "END OF NOV" ~ "Nov",
      period == "END OF DEC" ~ "Dec")
) |> 
  mutate(month_use = as.factor(month_names)
) |> 
  select(month_use, data_item, value, year)

storage_clean |> glimpse()
```

## Import production data

Here, I'll import my production data and clean it.

```{r prod_import}
production_dirty <- read_csv("data-raw/cheese_production.csv")
```
### Clean production data

There are NA values for Oregon in 2015 and New Jeresey in 2013 which are counted in other states, so I'm removing those rows.

```{r clean_production}
production_clean <- production_dirty |> 
  clean_names() |> 
  select(data_item, period, value, state, year) |> 
  filter(period == "YEAR") |> 
  drop_na() #removes rows with NA value

production_clean |> summary()
```

## Import consumption data

Since this file came in a poorly formatted Excel, I had to clean it up in Excel before importing here. I'll still clean names.

```{r consum}
library(readxl)

consum_dirty <- read_excel("data-raw/consum_cleaner.xlsx")
```

I'll still clean names and select just milk and cheese consumption.

```{r consum_clean}
consum_clean <- consum_dirty |> 
  clean_names() |> 
  select(year, fluid_beverage_milk, american_type, other_than_american, cottage)

consum_clean |> glimpse()
```

## Export my data

```{r export}
clean_adj_cheese |> write_rds("data-processed/01-cleaning.rds")
storage_clean |> write_rds("data-processed/01-storage.rds")
production_clean |> write_rds("data-processed/01-production.rds")
consum_clean |> write_rds("data-processed/01-consumption.rds")
```
