---
title: "Cleaning Data"
output:
  html_document:
    df_print: paged
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs") })
---

## Goals of this Notebook

- Import all my cheese data
- Clean names and dates
- Bind the files together
- Write the cleaned data

## About the data

I collected cheese price data from the [United States Department of Agriculture (USDA)](https://mymarketnews.ams.usda.gov/public_data). It ranges from 2000 to 2022, but structure of it changed after 2018. From 2000 to 2018, data was aggregated in one sheet. After 2018, the USDA created an API that recorded each year's data individually for each kind of cheese. I'll need to merge these files together.

One thing to note is that I'll be focusing on the import (not domestic) prices for this cheese to see how it trends over time. I also want to note that the price is in dollars per pound. You can also check out these [FAQs](https://mymarketnews.ams.usda.gov/faqs) about USDA market data.

## Setup

I'm loading the tidyverse library and lubridate package so I can clean up my data.

```{r setup}
library(tidyverse)
library(lubridate)
library(dplyr)
library(janitor)
```

## Import data

I'll import my first file here, which ranges from January 2000 to February 2018. I'll filter it so I'm looking at just the domestic cheese. I'll also remove repeated rows.

Then, I'll fix my dates so R reads them as dates.

```{r first_import}
thru_2018_clean <- read_csv("data-raw/thru_2018.csv") |> 
  distinct() |> #I'm using this to remove duplicate rows
  clean_names() |> 
  filter(
    region != "FOREIGN" #I don't want the foreign cheese
    ) |> 
  mutate(
    date = mdy(date)
  ) |> 
  select(
    date, type, high_price, low_price, region)

thru_2018_clean |> glimpse()
```

Now I'll import all the sheets that came after 2018. I put the midwest, northeast and west files for each year following 2018 in a folder called file-list and import them all here.

```{r list_import}
list_of_files <- list.files(path = "file-list", recursive = TRUE,
                            pattern = "\\.csv$", 
                            full.names = TRUE) #imports the file list

cheese_dirty <- list_of_files |> 
  purrr::set_names(nm = (basename("file-list") |>  tools::file_path_sans_ext())
) |> 
  purrr::map_df(read_csv, 
                col_names = TRUE) #sets names

cheese_dirty
```

Now I'll fix my names. In one data fram they are all uppercase, so I'll make sure it matches.

```{r names}
cheese_names <- cheese_dirty |> 
  mutate_if(is.character, str_to_upper)

cheese_names
```

Now I'll get rid of unnecessary columns and fix my dates. I'll also filter the date range so it will pick up where the other sheet left off.

```{r clean_data}
cheese_clean <- cheese_names |> 
  clean_names() |> 
    mutate(
    date = mdy(report_begin_date),
    low_price = price_min,
    high_price = price_max,
    type = group
) |> 
  filter(date > 02-05-2018,
         application == "DOMESTIC" #to remove foreign cheese
) |> 
  select(date, region, low_price, high_price, type)

cheese_clean
```

Now I'll bind my 2000 to 2018 data with my data from 2018 on.

```{r bind_rows}
all_cheese <- cheese_clean |> 
  bind_rows(thru_2018_clean)

all_cheese |> summary() #check my date range
```
## Adjust for Inflation

Now I want to adjust my prices for inflation. I'll be using the [average yearly Consumer Price Index for Urban Consumers, or CPI-U](https://www.bls.gov/bls/archived_sched.htm) from the Bureau of Labor Statistics to calculate each year's cheese prices adjusted to 2015 dollars. First, I need to make a year column.

```{r yr}
cheese_yrs <- all_cheese |>
  mutate(
    yr = year(date))

cheese_yrs
```

Now I'll divide the average CPI for each year by the 2015 CPI. Then,  I'll multiply it by each price in order to get a column where every price in my datast is adjusted to 2015 dollars.

A CPI estimate for 2022 is based on the change in the CPI from first quarter 2021 to first quarter 2022.

```{r case_when}
adj_cheese <- cheese_yrs |>
  mutate(
    adj_high_price = case_when(
      yr == 2000 ~ high_price*237.017/172.2,
      yr == 2001 ~ high_price*237.017/177.1,
      yr == 2002 ~ high_price*237.017/179.9,
      yr == 2003 ~ high_price*237.017/184.0,
      yr == 2004 ~ high_price*237.017/188.9,
      yr == 2005 ~ high_price*237.017/195.3,
      yr == 2006 ~ high_price*237.017/201.6,
      yr == 2007 ~ high_price*237.017/207.3,
      yr == 2008 ~ high_price*237.017/215.3,
      yr == 2009 ~ high_price*237.017/214.3,
      yr == 2010 ~ high_price*237.017/218.1,
      yr == 2011 ~ high_price*237.017/224.9,
      yr == 2012 ~ high_price*237.017/229.6,
      yr == 2013 ~ high_price*237.017/233.0,
      yr == 2014 ~ high_price*237.017/236.7,
      yr == 2015 ~ high_price*237.017/237.0,
      yr == 2016 ~ high_price*237.017/240.0,
      yr == 2017 ~ high_price*237.017/245.1,
      yr == 2018 ~ high_price*237.017/251.1,
      yr == 2019 ~ high_price*237.017/255.7,
      yr == 2020 ~ high_price*237.017/258.8,
      yr == 2021 ~ high_price*237.017/271.0,
      yr == 2022 ~ high_price*237.017/294.4
      ),
  adj_low_price = case_when(
      yr == 2000 ~ low_price*237.017/172.2,
      yr == 2001 ~ low_price*237.017/177.1,
      yr == 2002 ~ low_price*237.017/179.9,
      yr == 2003 ~ low_price*237.017/184.0,
      yr == 2004 ~ low_price*237.017/188.9,
      yr == 2005 ~ low_price*237.017/195.3,
      yr == 2006 ~ low_price*237.017/201.6,
      yr == 2007 ~ low_price*237.017/207.3,
      yr == 2008 ~ low_price*237.017/215.3,
      yr == 2009 ~ low_price*237.017/214.3,
      yr == 2010 ~ low_price*237.017/218.1,
      yr == 2011 ~ low_price*237.017/224.9,
      yr == 2012 ~ low_price*237.017/229.6,
      yr == 2013 ~ low_price*237.017/233.0,
      yr == 2014 ~ low_price*237.017/236.7,
      yr == 2015 ~ low_price*237.017/237.0,
      yr == 2016 ~ low_price*237.017/240.0,
      yr == 2017 ~ low_price*237.017/245.1,
      yr == 2018 ~ low_price*237.017/251.1,
      yr == 2019 ~ low_price*237.017/255.7,
      yr == 2020 ~ low_price*237.017/258.8,
      yr == 2021 ~ low_price*237.017/271.0,
      yr == 2022 ~ low_price*237.017/294.4
    ))

adj_cheese |> summary() #checking columns
```

## Export my data

```{r export}
adj_cheese |> write_rds("data-processed/01-cleaning.rds")
```
